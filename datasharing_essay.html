<h2>Public-private cooperation: Data sharing and transparency in the mobility sector</h2>
<p>Access to mobility and the capability to commute feasibly to work, education, and cultural and social events is a requisite for equality of opportunity. Effectively instantiating this idea, the Los Angeles Department for Transportation launched Universal Basic Mobility Pilot on April 26, 2022 (Hill, 2022). The program will invest nearly $18 million to bring subsidised and expanded public transportation services at the South LA Transit Empowerment Zone (SLATE-Z). Carsharing and Demand Responsive Transportation (DRT) facilities are planned to be introduced in addition to funded access to the metro, bus, and rail infrastructure. Indeed, emerging business models including shared mobility, and integrated public-private and multi-modal urban systems are gaining traction in transportation industries across the globe, and high-grade, instantaneous data are being generated in volumes. Analysis of this data accumulated, and stored by the private emerging transportation industry can reveal mobility behaviours and choices that can be exploited for public welfare.</p>
<p>However, private Transport Network Companies (TNCs) like Uber and Lyft have incessantly resisted requests for data from public authorities, and a lack of algorithmic transparency with regards to frequency, pricing, and remuneration for transportation services persists. This reluctance to share intelligence is evident in that Uber has actively pursued reducing reporting obligations in nearly 80% of regulated requests for data access (Tsay et al. 2016, as cited in Dijck et al., 2018)</p>
<br>Not only are public authorities unable to hold TNCs accountable for passenger safety, consumer rights, affordability, and inclusivity, there is no way for city authorities to tap into the potential of this data to build enriched models of demand and supply, and analyse policy ramifications. Considering the emerging integrated-mobility trends, this has adversarial repercussions for provision of accessible and sustainable transportation services. For instance, monitoring and regulation of greenhouse gas emission and congestion-induced pollution suffers due to lack of access to data and opacity of algorithms. 
<br>In recent years, few public agencies in jurisdictions with significant market sizes have managed to obtain highly aggregated data for regulatory purposes, though this data is not granular enough to extract meaningful insights into the operation network (Tsay et al. 2016, as cited in Dijck et al., 2018). In this essay, the transportation sector will be studied to motivate an analysis of exigent issues of public-private data sharing and algorithmic transparency. The trial between defendants Rasier (Uber) and Lyft, and plaintiffs City of Seattle and analyst Jeff Kirk for TNCs disclosure of aggregated data is used to support a subsequent comparative analysis to determine an appropriate data governance system for managing public-private cooperation. Following this, the value of algorithmic transparency is investigated with illustrative support of a study conducted at the University of Washington to verify disparate impact of pricing algorithms on the aggregated data disclosed by TNCs in Chicago. 
<br>As a large ride-hail platform in the sharing economy, Uber leverages its role as an intermediary between drivers and passengers to derive significant economic value from data collected on the interactions between these actors. Data on routes, ride-related variables including acceleration and break points, origin and destination factors in conjunction with a multitude of passenger and driver behaviour information all contribute towards maximisation of producer surplus. This is achieved through algorithms that are designed to price-discriminate, to monitor and nudge drivers via a bespoke reputation system, to optimise allocation of routes in real-time etc. Evidently, this data on its own is not valuable in absence of the manipulative tools and capacities, the regulated and incentivised purpose for this manipulation, and the collection of people ultimately impacted by the manipulation of data. It becomes meaningful only when linked and analysed with well-functioning software. 
<br>The case in consideration is the Lyft, Inc. and Rasier, LLC v City of Seattle and Jeff Kirk, decided at the Supreme Court of the State of Washington on May 31, 2018 (Lyft. Inc. v. City of Seattle, 2018). The respondents Lyft and Rasier, where the latter is a wholly-owned subsidiary of Uber Technologies, operate as ride-hailing or Transportation Networking Companies (TNC) in several locations around the world, including at Seattle. The motion was for Lyft and Rasier to submit quarterly reports including pick-up and drop-off zip codes, proportion of rides completed at each zip code among other data. The basis of defendant’s argument was that these quarterly zip code reports consisted of “trade secrets” protected under the Uniform Trade Secrets Act (UTSA), a piece of litigation created by the Uniform Law Commission, and adopted across 47 states in the USA including Washington.
<br>First, the invalidity of “trade secrets” as an explicitly stipulated exemption under the Public Records Act, the court was determined to judge whether the UTSA could be called upon to fulfil an “other statute” classification in the PRA based on a review of Lyft/Rasier zip code reports to the City of Seattle. Under the UTSA, a “trade secret” consists of “information, including a formula, pattern, compilation, program, device, method, technique, or process that: a) Derives independent economic value, actual or potential, from not being generally known to, and not being readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use; and b) is the subject of efforts that are reasonable under the circumstances to maintain its secrecy”. To assess the first point, the possibility for access to the complete dataset through repeated bidding for extracts of zip code data was analysed; with regards to the second point, efforts expended by both Uber and Lyft to prevent access to its data by competitors were measured. 
<br>In establishing economic value for the zip code data, and obtaining proof regarding the efforts made by TNCs in guarding this data against competitors, the court concluded that the “zip code records likely meet the definition of ‘trade secrets’ under the UTSA”. The court found value in the zip code reports as a spatial indicator of revenue generation and as a strategic indicator for marketing new products. It is worth noting however that this economic value of code reports as revenue and marketing indicators can be realised only in context of formation or transformation of corporate policy decisions upon analysis of these indicators. In addition, the court recognised the efforts made by TNCs in guarding zip code data using suitable methodologies and policies. 
<br>Acknowledging the duty of the City of Seattle to divulge information when required under the PRA, the defendant TNCs were also required to prove that disclosure of zip code data to public authorities “would clearly not be in public interest and would substantially and irreparably damage any person, or… vital governmental functions”. However, the TNCs failed to furnish any evidence for either the lack of usefulness of this data in public services, or any harm or damage from this disclosure, substantial or not, to governmental functions. Furthermore, insisting on the competitive advantage obtained by access to the data, the defendants claimed that disclosure of this data to public authorities would create an “unfair playing field” and “regulate [Lyft] out of existence. This corroborates the idea that adversarial interoperability may be a viable strategy for platforms seeking to expand the number and size of new players in the market. By hijacking network effects of TNCs like Uber and Lyft through data-powered development and connection of novel services and products with services already offered, competitive advantage can theoretically be lost. However, neither Lyft nor Rasier were able to quantify the economic benefit that the competitor would derive if data were shared with the public authority. Additionally, the fact that all TNC drivers and by extension all connected members of public already have knowledge of the areas and zip codes where demand for rides is higher during any typical day was raised. This refuted the argument that competition could benefit from any novel information if data were disclosed.
<br>Advocates of the closed data governance system in this context would also argue that because of the data being significant algorithmic components, the result of considerable financial investments and personal efforts, and as currencies for exchange and as tokens of personal identity, that the commercial value of data makes it more suitable to be classified as a private rather than a public good. 
<br>Firstly, I disagree with TNCs claim that standardised zip code or other specific variable reports derive value from considerable financial investment in their creation because this shrouds evidence that the underlying technological infrastructure consists mainly of sunk costs (Such as towers, cables, servers, networks, and software systems) that do not depreciate in value with transfer of information. Indeed, in this case neither Uber nor Lyft could provide quantitative evidence of significant cost incurred in delivery of processed data to the City of Seattle. </p>

<br>Secondly, TNCs’ claim that data collected by them should be qualified as intellectual property rests on the questionable assumption that a statutory protection for infringement of these rights can be sought for data aggregated from diverse independent sources as a protectable compilation. While vertical integration allows for potentially unique or novel compilations of data (“But to qualify for protection as a trade secret, the combination must still be shown to have novelty and uniqueness” – Woo, 137 Wn. App. At 488-89), I still insist that due to a high level of overlap between the users and partners of competitive firms in the TNC sector, a data compilation cannot assume protection rights. This result was corroborated by the court’s finding of no proof for novelty in compilation/aggregation. </p>

<br>Conventional wisdom has it that open data is in general more amenable to public welfare than data siloed in private corporations. Pollock (2009) emphasizes that open data will lead to innovative products that will create new markets, and will produce consumer surplus value generating significant public goods. Fioretti (2011) responds to naysayers of open data and their argument about privacy issues by claiming that majority of data that are directly related to an individual i.e. personal data like their name and address, are either not published, or simply not demanded. In general, two ideologies support this belief – that all data is deprived of ownership and thus should be transported without transactional regulation, and that given data hold potential to be tapped into for the benefit of humanity, it is a moral responsibility of data workers to enable unrestricted interoperability on the data generated and collected across and beyond organisational, geographical, and political boundaries. 

<br>Although I agree with Pollock and Fioretti up to a point, I cannot accept the overall conclusion that open data is always suitable in the case of TNCs like Uber and Lyft. Maintaining a large-scale open data project between TNCs and public authorities across cities, regions, and countries would require significant funding with respect to skilled staffing and suitable physical capital. Clearly, the economic viability of building a secure and sustainable data-cooperative is unclear at present. 

<br>Additionally, on the point of lack of demand and hence manipulation of personal data, it must be noted that widespread integration of diverse datasets is becoming a ubiquitous phenomenon. These linkages make it possible for personal data to be recovered even as parts within the sum do not contain any privacy-threatening information. 
<br>Finally, a pilot data-sharing infrastructure called “Collaborative Data Trust (CDT)” has already been deployed in Seattle to enable data sharing between public agencies, private organisations, and academicians (Young, M., 2019). Data trusts are legal structures that provide autonomous stewardship of data (Open Data Institute, 2019). Data workers who collect, store, and use data allow an independent group to create regulations for access and usage of this data, thus delegating responsibility to a third-party to manage its flow and integration. Young et al. conducted an independent analysis and concluded in favour of this governance system, claiming that it had made viable the sharing of data and algorithmic information while protecting privacy and preserving competitive interests. A CDT as deployed in Seattle is described by the Young et. Al. as a technological-legal system which demands the release and deposition of customised synthetic datasets to the data trust, accompanied with structured usage contracts to control access to granular, sensitive data. The authors insist that by facilitating application of differential privacy to generate artificial datasets, CDTs can be expected to successfully enforce conformity with high privacy standards of shared data. Specifically, this can be achieved by connecting rich datasets to the expertise required to create differential privacy mechanisms appropriate for each use case, and communicating the assumptions on which DP mechanisms are based, and using legal agreements to reach shared understanding with data contributors as to their contents and allowed uses. Furthermore, asserting that in light of the duopolistic nature of the TNC market mere aggregation does not protect a firm’s privacy and competitive interests, the authors offer support to their belief that CDT may help overcome this obstacle. 
<br>I endorse the Collaborative Data Trust governance system for data sharing between TNCs and public authorities, independent researchers because of the following reasons - not only does this infrastructure have potential to get around the most common, yet exigent reservations, the independent constitution of such an infrastructure can also account for the widely diverging interests of powerful TNCs and government agencies (Open Data Institute, 2019). Finally, if structured in a way to create revenue, a trust could also help generate an economically feasible link and reduce fiscal burden on data sharing between private and public authorities.
<br>Putting forward a successful case for public-private data cooperation, the City of Seattle and Jeff Kirk set a precedent that would follow in other cities across the USA, including the City of Chicago. A data sharing linkage was successfully established in Chicago in 2018, and has continued to present day (Freund, 2019). 
<br>To examine any bias, inadvertent or intended, in the provision of on-demand transportation services by TNCs in areas of differential demographic makeup within the city of Chicago, Caliskan and Pandey (2021) at the University of Washington conducted a study to measure partial associations with fare pricing of various stereotypical characteristics and social classes based on race, economic status, religion etc. Critically, it was found that on trips originating or concluding in areas with a higher proportion of people of colour, or those living below poverty line, the prices charged were higher. 
<br>In measuring bias of machine learning algorithms, the employment of ‘disparate impact’ is a point of contention. On the one hand, some argue that disparate impact allows for discrimination in practice, if not in explicit intent, to be detected and analysed. This is made possible by computing the overall percentage of positive or negative classification rates between protected and non-protected groups (Binns, 2018). On the other hand, some including Dwork et. Al (2012) contend that this fails to account for discrimination which is explainable in terms of legitimate grounds. Joe Biden’s nominee for attorney-general, John Kennedy even questioned whether disparate impact is “just a product of the numbers” (The Economist explains, 2021). My own view is that within the context of this problem the metric is a valid measurement of discrimination because of a failure to prove objective justification.

<br>Objective justification gives a defence for applying a policy, rule, or practice that would otherwise be unlawful discrimination (Words..Equality Act, 2018). To prove it, it must be shown that the policy or action or in this case, the prices charged to passengers are ‘a proportionate means of achieving a legitimate aim’. This ‘aim’ is required to be a real, objective consideration and not in itself discriminatory. For instance, if the aim is simply to reduce costs irrespective of and neglecting any varying impact, this aim would not be considered legitimate. Considering the non-public welfare motivations at for-profit  TNCs like Uber and Lyft, I insist that the utilisation of disparate impact as a measurement for inadvertent or intentional discrimination is valid.
<br>Given this assumption, differential prices need to be analysed in the context of the Surge Pricing mechanism, which is a well-known, albeit controversial algorithm that manages supply and demand of services provided by Uber. Prices increase to mitigate an imbalance created in areas where demand for trips is higher than supply of drivers. Surprisingly, despite higher prices found in depressed and mostly non-white areas, demand for trips was found to be relatively lower in these regions. Caliskan and Pandey concluded that higher prices in this context could be explained by some or all of the following three reasons – 1. Demand for travelling to and from the business, and arts district for employment-related purposes; 2. Incorporation of driver preferences in supply allocation; 3. Artificially directing supply of drivers towards affluent and economically active areas would inflate demand and prices in low-income areas. To mitigate the disparate impact, besides recommending accounting for differences in socio-economic characteristics including demographic makeup and spatial economics in the design of dynamic pricing algorithms, Caliskan and Pandey (2021) conclude by claiming that “algorithmic bias cannot be mitigated without algorithmic transparency”.  
<br>I strongly agree with the weightage given to algorithmic transparency, a point that needs emphasizing as many studies in the ethical domain have shown that processes involving algorithmic decision-making are much more amenable to auditing for disparate impact, disparate treatment, and discriminatory motivation as opposed to human decision-making. This is because like humans, algorithms and the pathways to final decisions associated with them can be undecipherable and opaque. However, unlike humans these pathways can be audited, validated, experimented with, and designed. By testing the data input into an algorithm, it is possible to know exactly what variables are influential, how they are weighted, when they interact with other variables and so on. With humans on the other hand, Kleinberg et al. (2018) describe how knowledge of the factors which influenced choices can often remain out of reach due to unconscious or implicit biases against certain groups. They go on to insist upon the feasibility of regulating decision-making performed by algorithms as systemising methodology for designing algorithms, and specifying recordkeeping conditions can be achieved via accessing and analysing both outputs returned by the decision-making process, as well as the training data that went into the process.

<br>Although I agree with the author’s central claim that the opportunity to ascertain discrimination is greater with algorithmic relative to human decision-making, I have mixed feelings about the conditions placed on suitable environments for this to apply. The requisite for all components, including training data, of an algorithm to be made available for examination and experimentation is at least presently, quasi-idealistic. Indeed, the lack of transparency with regard to the way algorithms balance supply and demand, set prices, wages, and manage drivers (“entrepreneurs”) using an opaque reputation system has been one of the defining characteristics of platforms in transportation sector. This prevents not just detection and mitigation of discrimination from algorithms, but also forestalls any progress in transforming algorithms to potentially counter existing inequalities in the social domain and consequently, the training data. 

<br>Ultimately, what is at stake here is public welfare, but more specifically the assurance of equitable access to opportunities to safeguard health, work, and wellbeing. A well-operating public transportation sector is a heralder of equitable economic growth and strengthened social ties between communities. I would argue that because the disadvantaged face higher prices in relation to the more privileged, especially considering the shift away from public transportation in the more affluent regions which in turn deepens an imbalance in the provision of transportation services, they are forced into a vicious cycle where they remain disadvantaged. Grabar (2016) notes how recently in Detroit, a local referendum resulted in the scrapping of investment in the public transport system where local rail and buses were decried as “dinosaur mass transit” in the era of TNCs. Technological advancement is outstripping the pace of research and ethical policymaking and regulation. Considering the significant impact on inclusivity, social welfare, and economic growth of inequitable access to reliable transportation, this problem deserves more attention.  

<h4>REFERENCES</h4>
<i>
1.	Hill (2022 ) https://www.itsinternational.com/its17/its9/news/universal-basic-mobility-hits-la
2.	José van Djick (2018) Urban Transport in José van Djick , Thomas Poell, and Martijn de Waal (2018) The Platform Society [e-book]  Oxford Scholarship Online  DOI: 10.1093/oso/9780190889760.001.0001
3.	Tsay, S.P., Accuardi, Z., Schaller, B. and Hovenkotter, K. (2016) Private mobility, public interest: how public agencies can work with emerging mobility providers.
4.	Lyft. Inc. v. City of Seattle (2018) Slip Opinion. Available at: <https://www.courts.wa.gov/opinions/pdf/940266.pdf>
5.	Open Data Institute, Personal data in transport: exploring a framework for the future (2018)  Available at: https://theodi.org/wp-content/uploads/2018/06/OPEN-Personal-data-in-transport-.pdf
6.	Pollock (2009) The Economics of Public Sector Information
7.	Fioretti, M., (2011) Open Data: Emerging trends, issues and best practices. Laboratory of.
8.	Grabar, H. (2016) “‘They Can Just Take an Uber’: Cities Are Cutting Transportation Service Because They Think Uber Will Fill the Gap. They’ll Regret It.” Slate.com Available at: http://www.slate.com/articles/business/metropolis/2016/12/cities_are_cutting_transportation_service_because_they_think_uber_will_fill.html.
9.	Young, M., Rodriguez, L., Keller, E., Sun, F., Sa, B., Whittington, J. and Howe, B., (2019)  Beyond open vs. closed: Balancing individual privacy and public accountability in data sharing. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 191-200).
10.	Open Data Institute (2019) Data trusts Available at: http://theodi.org/wp-content/uploads/2019/04/ODI-Data-Trusts-B3-Leaflet-web-2.pdf
11.	Freund (2019) Chicago first city to publish data on ride-hailing trips, drivers, and vehicles. Available at: https://chicago.curbed.com/2019/4/15/18311340/uber-lyft-chicago-data-fares-drivers
12.	Pandey, A. and Caliskan, A. (2021) Disparate Impact of Artificial Intelligence Bias in Ridehailing Economy's Price Discrimination Algorithms. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society (pp. 822-833).
13.	Dwork, C., Hardt, M., Pitassi, T., Reingold, O. and Zemel, R. (2012) Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference (pp. 214-226).
14.	 The Economist explains (2021) What does ”disparate impact” mean? Available at: https://www-economist-com.uoelibrary.idm.oclc.org/the-economist-explains/2021/03/03/what-does-disparate-impact-mean
15.	Words and terms used in the Equality Act (2018) Equalityhumanrights.com Available at: https://www-economist-com.uoelibrary.idm.oclc.org/the-economist-explains/2021/03/03/what-does-disparate-impact-mean
16.	Kleinberg, J., Ludwig, J., Mullainathan, S. and Sunstein, C.R. (2018) Discrimination in the Age of Algorithms. Journal of Legal Analysis, 10, pp.113-174.
17.	Binns, R. (2018) Fairness in machine learning: Lessons from political philosophy. In Conference on Fairness, Accountability and Transparency (pp. 149-159). PMLR.
18.	Leonelli, S., (2020) Governance of data journeys. In Data journeys in the sciences (pp. 136-154). Springer, Cham.
</i>
